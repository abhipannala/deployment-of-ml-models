{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "Pipeline is a powerful tool to standardise your operations and chain then in a sequence, make unions and finetune parameters. In this example we will:\n",
    "* create a simple pipeline of default sklearn estimators/transformers\n",
    "* create our own estimator/transformer\n",
    "* create a pipeline which will process features in a different way and then join them horizontally\n",
    "* finetune some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T03:21:45.658658Z",
     "start_time": "2019-11-23T03:21:43.940347Z"
    },
    "_cell_guid": "3adf2a49-3ed9-4b69-afde-de4881aaa096",
    "_uuid": "fe97cb2c16e7cba66c8c34e87b34368de5897e75"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T03:21:46.518350Z",
     "start_time": "2019-11-23T03:21:45.660557Z"
    },
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'D:\\Machine Learning\\Deployment of Machine Learning Models\\Section 4 Building a Reproducible Machine Learning Pipeline\\sklearn Pipeline\\Data\\jigsaw-toxic-comment-classification-challenge\\train.csv')\n",
    "x = df['comment_text'].values[:5000]\n",
    "y = df['toxic'].values[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T03:21:46.524249Z",
     "start_time": "2019-11-23T03:21:46.520257Z"
    },
    "_cell_guid": "29546f9f-2688-4664-956f-73f7963cc7ab",
    "_uuid": "e066a6f8ef02480d45d7f9bed4df215d4ef50caf"
   },
   "outputs": [],
   "source": [
    "# default params\n",
    "scoring='roc_auc'\n",
    "cv=3\n",
    "n_jobs=-1\n",
    "max_features = 2500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a4fda56f-40a5-4b09-8a86-1593d28c12ef",
    "_uuid": "b523f647558305f3291f54c472b42bda04679ce4"
   },
   "source": [
    "Simple pipelines of default sklearn TfidfVectorizer to prepare features and Logistic Reegression to make predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T03:21:48.499961Z",
     "start_time": "2019-11-23T03:21:46.525245Z"
    },
    "_cell_guid": "fd6a6785-75d6-41f3-b2da-19cdfcbcba5f",
    "_uuid": "2b053fe5405199e12e9e83a37a8136d511f4deaa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91248134, 0.92889109, 0.92437274])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(max_features=max_features)\n",
    "lr = LogisticRegression()\n",
    "p = Pipeline([\n",
    "    ('tfidf', tfidf),\n",
    "    ('lr', lr)\n",
    "])\n",
    "\n",
    "cross_val_score(estimator=p, X=x, y=y, scoring=scoring, cv=cv, n_jobs=n_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fad2f328-700f-4252-ad18-e6426d5f6bd9",
    "_uuid": "a8b9e8588cdf43541eeace1040be1d8290743e86"
   },
   "source": [
    "Lets create or own Estimator to reproduce Jeremy`s notebook in pipelines. This estimator is created with sklearn BaseEstimator class and needs to have fit and transform methods. First Pipeline calls fit methods to learn your dataset and then calls transform to apply knowledge and does some transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T03:21:48.508991Z",
     "start_time": "2019-11-23T03:21:48.501958Z"
    },
    "_cell_guid": "6d13a924-89e4-4d54-b65f-798389fb9117",
    "_uuid": "f3e312525331193e2607cd4949c777899fbc95a8"
   },
   "outputs": [],
   "source": [
    "class NBFeaturer(BaseEstimator):\n",
    "    def __init__(self, alpha):\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def preprocess_x(self, x, r):\n",
    "        return x.multiply(r)\n",
    "    \n",
    "    def pr(self, x, y_i, y):\n",
    "        p = x[y==y_i].sum(0)\n",
    "        return (p+self.alpha) / ((y==y_i).sum()+self.alpha)\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        self._r = sparse.csr_matrix(np.log(self.pr(x,1,y) / self.pr(x,0,y)))\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x):\n",
    "        x_nb = self.preprocess_x(x, self._r)\n",
    "        return x_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T03:21:49.799485Z",
     "start_time": "2019-11-23T03:21:48.510940Z"
    },
    "_cell_guid": "4f854959-d846-4aff-bb17-326ec45afbb8",
    "_uuid": "a79425633291ff8adba286fc423f5511f8dcaa30"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91851711, 0.93572898, 0.91808511])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(max_features=max_features)\n",
    "lr = LogisticRegression()\n",
    "nb = NBFeaturer(1)\n",
    "p = Pipeline([\n",
    "    ('tfidf', tfidf),\n",
    "    ('nb', nb),\n",
    "    ('lr', lr)\n",
    "])\n",
    "\n",
    "cross_val_score(estimator=p, X=x, y=y, scoring=scoring, cv=cv, n_jobs=n_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9aecfcc7-aafe-46ac-aeac-f7b4741e3285",
    "_uuid": "d7fd499f68f9ae2c325b26b093add73cec6e568e"
   },
   "source": [
    "Lets add one more custom Estimator to our pipeline, called Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T03:21:49.811456Z",
     "start_time": "2019-11-23T03:21:49.803474Z"
    },
    "_cell_guid": "79f83339-5bf4-44cf-a09a-1577f2033cf2",
    "_uuid": "7b2b18feec6f72069c638c577be76967ef72de56"
   },
   "outputs": [],
   "source": [
    "class Lemmatizer(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.l = WordNetLemmatizer()\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x):\n",
    "        x = map(lambda r:  ' '.join([self.l.lemmatize(i.lower()) for i in r.split()]), x)\n",
    "        x = np.array(list(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T03:21:54.089634Z",
     "start_time": "2019-11-23T03:21:49.815443Z"
    },
    "_cell_guid": "41fcfc3b-8c4c-483c-9891-2445c0a1f0cd",
    "_uuid": "4f8a3e84c330c42e9fa542a74fc0c85f58bed5a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9267607 , 0.93755361, 0.91863238])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = Lemmatizer()\n",
    "tfidf = TfidfVectorizer(max_features=max_features)\n",
    "lr = LogisticRegression()\n",
    "nb = NBFeaturer(1)\n",
    "p = Pipeline([\n",
    "    ('lm', lm),\n",
    "    ('tfidf', tfidf),\n",
    "    ('nb', nb),\n",
    "    ('lr', lr)\n",
    "])\n",
    "\n",
    "cross_val_score(estimator=p, X=x, y=y, scoring=scoring, cv=cv, n_jobs=n_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9fbe8d22-a843-459d-9b65-c90af53e68b3",
    "_uuid": "de7ba14d6a4dc97f40d5b3c0e4862b2529666e9a"
   },
   "source": [
    "Pipelines also allow you to process different features in a different way and then concat the result. FeatureUnion halps us with this. Lets create additional tfidf vectorizer for chars and join its results with words vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T03:21:58.232508Z",
     "start_time": "2019-11-23T03:21:54.091587Z"
    },
    "_cell_guid": "47ab51ae-9a7a-4b1e-b01d-bfd5ea20eb62",
    "_uuid": "2e85df4ba89fec86a4db4fd1a699421c4b208ed2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94049207, 0.94488786, 0.93058846])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_features = 2500\n",
    "lm = Lemmatizer()\n",
    "tfidf_w = TfidfVectorizer(max_features=max_features, analyzer='word')\n",
    "tfidf_c = TfidfVectorizer(max_features=max_features, analyzer='char')\n",
    "lr = LogisticRegression()\n",
    "nb = NBFeaturer(1)\n",
    "p = Pipeline([\n",
    "    ('lm', lm),\n",
    "    ('wc_tfidfs', \n",
    "         FeatureUnion([\n",
    "            ('tfidf_w', tfidf_w), \n",
    "            ('tfidf_c', tfidf_c), \n",
    "         ])\n",
    "    ),\n",
    "    ('nb', nb),\n",
    "    ('lr', lr)\n",
    "])\n",
    "\n",
    "cross_val_score(estimator=p, X=x, y=y, scoring=scoring, cv=cv, n_jobs=n_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ad916d6a-811c-4e1c-be13-03b8c5eb2ab5",
    "_uuid": "39007f3683aad3616f3815e56276acddb94e63db"
   },
   "source": [
    "Who does not like finetuning? Lets make it simple with pipelines  and GridSearchCV/RandomizedSearchCV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T03:22:06.159837Z",
     "start_time": "2019-11-23T03:21:58.234502Z"
    },
    "_cell_guid": "d66d2f18-f725-4ddf-9d78-94ffa5602bd4",
    "_uuid": "89dfc5aa716aa9c0b0ae6983fd8e49495e84433c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    4.7s finished\n",
      "C:\\Users\\puabh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([3.09293946, 2.10390925]),\n",
       " 'std_fit_time': array([0.76640666, 0.12394552]),\n",
       " 'mean_score_time': array([0.74468255, 0.92918086]),\n",
       " 'std_score_time': array([0.20834602, 0.04157243]),\n",
       " 'param_lr__C': masked_array(data=[3.0, 3.0],\n",
       "              mask=[False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_wc_tfidfs__tfidf_c__stop_words': masked_array(data=[2500, 5000],\n",
       "              mask=[False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_wc_tfidfs__tfidf_w__max_features': masked_array(data=[2500, 2500],\n",
       "              mask=[False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'lr__C': 3.0,\n",
       "   'wc_tfidfs__tfidf_c__stop_words': 2500,\n",
       "   'wc_tfidfs__tfidf_w__max_features': 2500},\n",
       "  {'lr__C': 3.0,\n",
       "   'wc_tfidfs__tfidf_c__stop_words': 5000,\n",
       "   'wc_tfidfs__tfidf_w__max_features': 2500}],\n",
       " 'split0_test_score': array([0.93779186, 0.93779186]),\n",
       " 'split1_test_score': array([0.9408574, 0.9408574]),\n",
       " 'split2_test_score': array([0.92735676, 0.92735676]),\n",
       " 'mean_test_score': array([0.93533694, 0.93533694]),\n",
       " 'std_test_score': array([0.00577833, 0.00577833]),\n",
       " 'rank_test_score': array([1, 1])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [{\n",
    "    'wc_tfidfs__tfidf_w__max_features': [2500], \n",
    "    'wc_tfidfs__tfidf_c__stop_words': [2500, 5000],\n",
    "    'lr__C': [3.],\n",
    "}]\n",
    "\n",
    "grid = GridSearchCV(p, cv=cv, n_jobs=n_jobs, param_grid=param_grid, scoring=scoring, \n",
    "                            return_train_score=False, verbose=1)\n",
    "grid.fit(x, y)\n",
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T03:22:11.141195Z",
     "start_time": "2019-11-23T03:22:06.161830Z"
    },
    "_cell_guid": "81ef5394-a195-401e-9b75-ee329e0d7f68",
    "_uuid": "ab36753d9d4d4fce580b418182cfd8da4fdb02f8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    2.4s finished\n",
      "C:\\Users\\puabh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([1.62332527]),\n",
       " 'std_fit_time': array([0.08461147]),\n",
       " 'mean_score_time': array([0.70545284]),\n",
       " 'std_score_time': array([0.08234663]),\n",
       " 'param_wc_tfidfs__tfidf_w__max_features': masked_array(data=[10000],\n",
       "              mask=[False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_wc_tfidfs__tfidf_c__stop_words': masked_array(data=[5000],\n",
       "              mask=[False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_lr__C': masked_array(data=[1.0],\n",
       "              mask=[False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'wc_tfidfs__tfidf_w__max_features': 10000,\n",
       "   'wc_tfidfs__tfidf_c__stop_words': 5000,\n",
       "   'lr__C': 1.0}],\n",
       " 'split0_test_score': array([0.95026446]),\n",
       " 'split1_test_score': array([0.95762254]),\n",
       " 'split2_test_score': array([0.94396264]),\n",
       " 'mean_test_score': array([0.95061788]),\n",
       " 'std_test_score': array([0.00558195]),\n",
       " 'rank_test_score': array([1])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [{\n",
    "    'wc_tfidfs__tfidf_w__max_features': [2500, 5000, 10000], \n",
    "    'wc_tfidfs__tfidf_c__stop_words': [2500, 5000, 10000],\n",
    "    'lr__C': [1., 3., 4.],\n",
    "}]\n",
    "\n",
    "grid = RandomizedSearchCV(p, cv=cv, n_jobs=n_jobs, param_distributions=param_grid[0], n_iter=1, \n",
    "                          scoring=scoring, return_train_score=False, verbose=1)\n",
    "grid.fit(x, y)\n",
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "47e2def8-42b5-4741-baed-41a52e5fc864",
    "_uuid": "ef7c893fafab6c10d4d9fee86c6f947cd03ebf47"
   },
   "source": [
    "Useful links:\n",
    "* http://scikit-learn.org/stable/modules/pipeline.html#pipeline\n",
    "* https://github.com/scikit-learn-contrib/project-template"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
